---
title: "Core_ERM_W2_notes"
author: "Xiaotian Tian"
format: pdf
editor: visual
---

# Week 2 Part 1: Research Plumbing 1

```{r}
options(crayon.enabled = FALSE) # suppress colorised warnings to be displayed correctly
gc() # garbage collection
rm(list = ls()) # clear variables
```

## Video

### Stroe and Read Data

-   `readr` package in tidyverse can load .csv or .tsv files smoothly

-   `readxl` imports .xls and .xlsx files

-   `haven` imports SAS, SPSS, and Stata files

Example use

```{r}
library(tidyverse)
```

Example of `read.csv()`

```{r}
url <- "https://ditraglia.com/data/height-handspan.csv"
height_handspan <- read.csv(url)

height_handspan
```

Example of `read_dta()`

```{r}
library(haven)
```

```{r}
url <- "https://ditraglia.com/data/lakisha_aer.dta"
lakisha <- read_dta(url)

lakisha
```

-   `getwd()` and `setwd()`

-   Beaware that, on Windows, we need to either use `/` or `\\`

    -   Better plan: use R Studio Projects and relative paths

## Wrangling Data

Sample data

```{r}
library(tidyverse)
set.seed(92815)
gradebook <- tibble(
  student_id = c(192297, 291857, 500286, 449192, 372152, 627561), 
  name = c('Alice', 'Bob', 'Charlotte', 'Dante', 
           'Ethelburga', 'Felix'),
  quiz1 = round(rnorm(6, 65, 15)),
  quiz2 = round(rnorm(6, 88, 5)),
  quiz3 = round(rnorm(6, 75, 10)),
  midterm1 = round(rnorm(6, 75, 10)),
  midterm2 = round(rnorm(6, 80, 8)), 
  final = round(rnorm(6, 78, 11)))
gradebook
```

### tidyselect

`tidyselect` arguments in `dplyr`

Example (easier ones)

```{r}
gradebook |>
  select(starts_with("quiz"))
```

```{r}
gradebook |>
  select(ends_with("2"))
```

```{r}
gradebook |>
  select(contains("iz"))
```

```{r}
gradebook |>
  select(num_range("quiz", 2:3)) # select based on both a prefix and a numeric range
```

We can even use regular expressions!!

```{r}
gradebook |>
  select(matches("quiz[0-9]+"))
```

`where()` takes a function as input and applies it to every column of th tibble and returns those where the function returns `TRUE`

```{r}
gradebook |>
  select(where(is.numeric))
```

### Column-wise Operations

```{r}
gradebook |>
  summarise(across(starts_with("quiz"), mean, .names = "{.col}_avg"))
```

`summarise(across(      ))`

-   1st argument: `.cols` specifies columns to work with

    -   specify explicitly using a vector `c("col1", "col2")`

    -   use `tidyselect`

-   2nd argument: `.fns` specifies function(s) to apply

-   3rd argument (optional): `.names()` sets rule for naming transformed columns, using syntax from the `glue` package

We can supply a custom function:

```{r}
zscore <- function(x) {
  (x - mean(x, na.rm = TRUE)) / sd(x, na.rm = TRUE)
}

gradebook |>
  summarise(across(starts_with("quiz"), zscore, .names = "{.col}_zscore")) |>
  select(ends_with("zscore"))
```

We can even supply a list of functions:

```{r}
mean_var <- list(
  mean = \(x) mean(x, na.rm = TRUE),
  var = \(x) var(x, na.rm = FALSE)
)

gradebook |>
  summarise(across(
    starts_with("quiz"),
    mean_var,
    .names = "{.col}_{.fn}"
  ))
```

Exercise C

```{r}
# 1
gradebook |>
  summarise(across(
    matches("quiz[\\d]?"),
    sd,
    .names = "{.col}_sd"
  ))
```

```{r}
# 2
starwars |>
  summarise(across(
    everything(),
    n_distinct,
    .names = "n_{.col}s"
  ))
```

```{r}
# 3
starwars |>
  group_by(homeworld) |>
  filter(n() >= 2) |>
  summarise(across(
    c(sex, species, eye_color),
    n_distinct,
    .names = "n_distinct_{.col}"
  ))
```

```{r}
# 4
starwars |>
  group_by(species) |>
  filter(n() >= 2) |>
  summarise(across(
    where(~ typeof(.) %in% c("integer", "double")), # ~ starts an anonymous function (like lambda in python) and . refers to the column being tested
    median,
    na.rm = TRUE,
    .name = "{.col}_median"
  ))
```

```{r}
# 5
starwars |>
  summarise(across(
    where(~ typeof(.) %in% c("integer", "double")),
    list("sd" = sd, "iqr" = IQR),
    na.rm = TRUE,
    .names = "{.col}_{.fn}"
  ))
```

### Recode

```{r}
star <- read_csv('https://ditraglia.com/data/STAR.csv')
```

Use `case_match()` from `dplyr` to recode values

```{r}
star <- star |>
  mutate(classtype = case_match(classtype,
                                1 ~ "small",
                                2 ~ "regular",
                                3 ~ "regular+aid"))
```

```{r}
star
```

## Producing Tables

Use reproducible tools like `knitr::kable`, `gt` and `modelsummary` to generate and format tables, and include them in *any* document format.

-   Today: [`datasummary`](https://vincentarelbundock.github.io/modelsummary/articles/datasummary.html) and [`knitr::kable`](https://bookdown.org/yihui/rmarkdown-cookbook/kable.html)

-   Future lectures: [`modelsummary`](https://vincentarelbundock.github.io/modelsummary/articles/modelsummary.html)

-   Some prefer [`stargazer`](https://cran.r-project.org/web/packages/stargazer/vignettes/stargazer.pdf). You can use this if you prefer.

-   For the ultimate in precision table creation, try [`gt`](https://gt.rstudio.com/).

```{r}
library(modelsummary)
```

```{r}
datasummary_skim(star)
```

We can compare summary statistics across categories defined by a "grouping" variable with syntax `datasummay_table( ~ [GROUPING_VAR], data)`

```{r}
star |>
  select(yearssmall, g4math, g4reading, classtype) |>
  datasummary_balance(~ classtype, data = _)
```

Customise table with `knitr::kable`:

```{r}
my_table <- star |>
  group_by(classtype) |>
  summarise(across(
    starts_with("g4"),
    \(x) mean(x, na.rm = TRUE),
    .names = "{.col}_avg"
  ))

my_table |>
  knitr::kable(
    digits = 1,
    caption = "Average grade 4 test scores",
    col.names = c("Class Type", "Math", "Reading")
    )
```

# Week 2 Part 2: Linear Regression

## Linear Regression Basics

```{r}
gc() # garbage collection
rm(list = ls()) # clear variables
library(tidyverse)
kids <- read_csv('https://ditraglia.com/data/child_test_data.csv')
kids
```

Clean up with [**`janitor`**](https://cran.r-project.org/web/packages/janitor/vignettes/janitor.html)**`:`**

```{r}
library(janitor)
kids <- clean_names(kids)
kids
```

Linear Regression with `lm([FORMULA], [DATAFRAME])`:

Formula Syntax:

-   `~` to separate LHS from RHS: Y from X

-   `+` to separate RHS variables: X1 from X2

```{r}
lm(kid_score ~ mom_iq + mom_age, data = kids)
```

Plot the regression line

```{r}
kids |>
  ggplot(aes(
    x = mom_iq, y = kid_score
  )) +
  geom_point() +
  geom_smooth(method = "lm") +
  xlab("Mom's IQ Score") +
  ylab("Child's Test Score (Age 3)")
```

Getting more from `lm()`

```{r}
reg1 <- lm(kid_score ~ mom_iq, kids)
str(reg1)
```

```{r}
coef(reg1)
```

```{r}
resid(reg1)[1:10] # only display the first 10
```

```{r}
fitted.values(reg1)[1:10] # only display the first 10
```

Summarising the output of `lm()`

```{r}
summary(reg1)
```

Looking inside `summary()`

```{r}
str(summary(reg1))
```

Accessing specific result from `summary()`

```{r}
summary(reg1)$r.squared
```

## Tidying up with `broom()`

Tidying up with `broom()` : `tidy()` returns a tibble with estimates, SEs, etc.

```{r}
library(broom)
tidy(reg1)
```

`glance()` returns a tibble with measurement of "model fit"

```{r}
glance(reg1)
```

and `broom` plays nicely with `dyplr`

```{r}
reg1 |>
  tidy() |>
  filter(term == "mom_iq") |>
  pull(p.value)
```

`augment()` ensembles a number of figures

```{r}
augment(reg1, kids)
```

## Dummy Variables

We can recode a variable into 2-category str variable and R will construct the dummy for us

```{r}
kids <- kids |>
  mutate(mom_education = if_else(mom_hs == 1, "HS", "NoHS"))

lm(kid_score ~ mom_education, kids)
```

Designate the baseline category:

```{r}
kids <- kids |>
  mutate(mom_education = fct_relevel(mom_education, "NoHS"))

lm(kid_score ~ mom_education, kids)
```

To generate a dummy for every value of a variable, use `factor([variable])` in your formula.

## R-formula

More on **R-formula**:

-   `y ~ x` is an R **formula**; use to specify a statistical model

-   Within a formula, certain characters have a special meaning

-   You’ve already met `~` and `+`

-   The rest are `.`, `-`, `1`, `:`, `*`, `^`, and `I()`.

-   `^` and `*` are more exotic; I’ll skip them here

-   See my [R Formula Cheatsheet](https://www.econometrics.blog/post/the-r-formula-cheatsheet/) for full details.

Regressing one variable on all other variables using `.`:

```{r}
lm(kid_score ~ ., kids)
```

Removing predictors with `-` :

```{r}
lm(kid_score ~ . - mom_hs, kids)
```

Remove the intercept by `-`

`1`:

```{r}
lm(kid_socre ~ . - 1, kids)
```

Regress only on an intercept:

```{r}
lm(kid_score ~ 1, kids)
```

Remove the intercept when having categorical dummies:

```{r}
lm(kid_score ~ mom_education - 1, kids)
```

Formulating new predictors:

```{r}
new_kids <- kids |>
  mutate(log_kid_score = log(kid_score),
         mom_age_sq = mom_age^2)
lm(log_kid_score ~ mom_age + mom_age_sq, new_kids)
```

A cleaner approach:

```{r}
lm(log(kid_score) ~ mom_age + I(mom_age^2), kids)
```

Adding interactions with `:`:

```{r}
lm(kid_score ~ mom_age:mom_iq, kids)
```

## Predicted Values

**Syntax**: `predict(object, newdata)`

```{r}
reg2 <- lm(kid_score ~ mom_iq * mom_education, kids) 
new_kids <- data.frame(mom_iq = c(100, 120, 80), 
                       mom_education = c('NoHS', 'HS', 'HS'))

predict(reg2, new_kids)
```

Predicting with `augment()`:

```{r}
augment(reg2, newdata = new_kids) |>
  rename(kid_score_pred = .fitted)
```

## Testing Linear Restrictions

`linearHypothesis()` from `car` provides F-test.

**Some Warnings**

-   Null hypothesis significance testing (NHST) is rarely the right tool for the job in applied work.

-   Have you see the memo on [p-values](https://www.amstat.org/asa/files/pdfs/P-ValueStatement.pdf)?

-   **Statistical Inference - Defense Against the Dark Arts**

-   See also: [FF-tests, R2R2 and Other Distractions](https://www.stat.cmu.edu/~cshalizi/mreg/15/lectures/10/lecture-10.pdf)

-   Today: assume *homoskedasticity*.

Testing $\beta_0 = \beta_1 = 1$:

```{r}
library(car)
linearHypothesis(reg1, c("mom_iq = 1", "(Intercept) = 1"))
```

Variants of the test:

Use the asymptotic $\chi^2$ distribution:

```{r}
linearHypothesis(reg1, c("mom_iq = 1", "(Intercept) = 1"), test = "Chisq")
```

## Making Nice Regression Tables

`modelsummary()` function for regression tables

```{r}
library(modelsummary)
```

```{r}
reg_pooled <- lm(kid_score ~ mom_iq, kids)
reg_hs_dummy <- lm(kid_score ~ mom_iq + mom_hs, kids)
reg_interact <- lm(kid_score ~ mom_iq * mom_hs, kids)
```

```{r}
modelsummary(reg_pooled)
```

Clean up results:

```{r}
modelsummary(reg_pooled, gof_omit = 'Log.Lik|R2 Adj.|AIC|BIC|F', fmt = 2, 
             title = 'Regression results for kids dataset', 
             notes = 'Source: all data were fabricated by the authors.') 
```

Results of Several Regressions:

```{r}
kids_regressions <- list(reg_pooled, reg_hs_dummy, reg_interact)
modelsummary(kids_regressions, gof_omit = 'Log.Lik|R2 Adj.|AIC|BIC|F', fmt = 2)
```

# Week 2 Part 3: Monte Carlo Simulation Basics in R

```{r}
.rs.restartR() # restart R session
```

```{r}
rm(list = ls()) # remove all variables
gc() # garbage collection
options(crayon.enabled = FALSE) # suppress colorised warnings to be displayed correctly
```

```{r}
library(tidyverse)
```

## Basics

Rough idea:

-   Independent draws from $U[0,1]$

-   Transform them into other probability distributions

`sample()`: draw from a vector in $R$:

```{r}
sample(
  c("A", "B", "C"),
  size = 10,
  replace = TRUE,
  prob = c(0.1, 0.1, 0.8)
)
```

Setting the seed:

```{r}
set.seed(114514)
```

## d/p/q/r of A Distribution

-   Base R has functions for many common RVs

-   Each RV has an abbreviation: e.g. `norm` for normal

-   Each RV has four related functions:

    -   `d` = density if continuous, mass function if discrete

    -   `p` = CDF

    -   `q` = quantile function (inverse CDF)

    -   `r` makes random draws

-   E.g. `dnorm()`, `pnorm()`, `qnorm()`, `rnorm()`

**Built-in Random Variables in R**

| **R commands** | **Distribution** |
|:-----------------------------------|:-----------------------------------|
| `d/p/q/rbeta` | [Beta](https://en.wikipedia.org/wiki/Beta_distribution) |
| `d/p/q/rbinom` | [Binomial](https://en.wikipedia.org/wiki/Binomial_distribution) |
| `d/p/q/rcauchy` | [Cauchy](https://en.wikipedia.org/wiki/Cauchy_distribution) |
| `d/p/q/rchisq` | [Chi-Squared](https://en.wikipedia.org/wiki/Chi-squared_distribution) |
| `d/p/q/rexp` | [Exponential](https://en.wikipedia.org/wiki/Exponential_distribution) |
| `d/p/q/rf` | [F](https://en.wikipedia.org/wiki/F-distribution) |
| `d/p/q/rgamma` | [Gamma](https://en.wikipedia.org/wiki/Gamma_distribution) |
| `d/p/q/rgeom` | [Geometric](https://en.wikipedia.org/wiki/Geometric_distribution) |
| `d/q/p/rhyper` | [Hypergeometric](https://en.wikipedia.org/wiki/Geometric_distribution) |

| **R commands** | **Distribution** |
|:-----------------------------------|:-----------------------------------|
| `d/p/q/rlogis` | [Logistic](https://en.wikipedia.org/wiki/Logistic_distribution) |
| `d/p/q/rlnorm` | [Log Normal](https://en.wikipedia.org/wiki/Lognormal_distribution) |
| `d/p/q/rnbinom` | [Negative Binomial](https://en.wikipedia.org/wiki/Negative_binomial_distribution) |
| `d/p/q/rnorm` | [Normal](https://en.wikipedia.org/wiki/Normal_distribution) |
| `d/p/q/rpois` | [Poisson](https://en.wikipedia.org/wiki/Poisson_distribution) |
| `d/p/q/rt` | [Student’s t](https://en.wikipedia.org/wiki/Student%27s_t-distribution) |
| `d/p/q/runif` | [Uniform](https://en.wikipedia.org/wiki/Continuous_uniform_distribution) |
| `d/p/q/rweibull` | [Weibull](https://en.wikipedia.org/wiki/Weibull_distribution) |

Example: Normal

-   Warning: R parameterises the Normal distribution in terms of its mean and *standard deviation!!!*

```{r}
mu <- 0
sd <- 1

# Normal PDF

normal_density <- tibble(x = seq(from = -4, to = 4, by = 0.01)) |>
  mutate(density = dnorm(x, mu, sd))

normal_density |>
  ggplot(aes(x, density)) +
  geom_line()
```

```{r}
# Normal CDF

normal_cdf <- tibble(x = seq(from = -4, to = 4, by = 0.01)) |>
  mutate(cdf = pnorm(x, mu, sd))

normal_cdf |>
  ggplot(aes(x, cdf)) +
  geom_line()
```

```{r}
# Normal Draws

set.seed(1234)

normal_sims <- rnorm(500, mu, sd)

tibble(normal_sims) |>
  ggplot(aes(x = normal_sims)) +
  geom_histogram(bins = 20)
```

Example: Binomial(10, 0.2)

```{r}
n <- 10
p <- 0.2

# pmf

binom_pmf <- tibble(x = 0:n) |>
  mutate(p = dbinom(x, n, p))

binom_pmf |>
  ggplot(aes(x = x, y = p)) +
  geom_point() +
  geom_segment(aes(xend = x, yend = 0)) +
  labs(title = "Binomial(10,0.2) pmf",
       y = "p(x)")
```

```{r}
set.seed(1693)

binom_sims = rbinom(500, n, p)

tibble(binom_sims) |>
  ggplot(aes(x = binom_sims)) +
  geom_bar()
```

## The Inverse Transformation Method and QQ Plots

The Inverse Transformation Method:

-   Already know how make uniform draws.

-   Simulate *arbitrary* RV with CDF F and quantile function Q.

-   **Inverse Transformation Method**

    1.  Generate U∼Uniform(0,1).

    2.  Set Y≡Q(U)⟹P(Y≤y)=F(y)

-   F continuous & strictly increasing $⟹Q=F^{-1}$.

-   Otherwise, Q is the [generalized inverse](https://en.wikipedia.org/wiki/Cumulative_distribution_function#Inverse_distribution_function_(quantile_function)) of F.

Example: Exponential(1)

![](images/clipboard-2172043404.png)

```{r}
u <- runif(1e5)
exp1_sims <- -log(1 - u)
tibble(x = exp1_sims) |>
  ggplot(aes(x)) +
  geom_histogram()
```

Quantile-Quantile (QQ) Plots

![](images/clipboard-2509058013.png)\
More details of QQ plots in [this blog post](https://www.econometrics.blog/post/thirty-isn-t-the-magic-number/).

Example: t Distribution with dof3

```{r}
t3_sims <- rt(500, df = 3)
tibble(x = t3_sims) |>
  ggplot(aes(sample = x)) +
  geom_qq() # default is N(0,1)
```

Plot a line through the 1st and 3rd quartiles:

```{r}
tibble(x = t3_sims) |>
  ggplot(aes(sample = x)) +
  geom_qq(distribution = qt, dparams = list(df = 3)) +
  geom_qq_line(col = "red", distribution = qt, dparams = list(df = 3))
```

Another example: Exp(1) simulation

```{r}
tibble(x = exp1_sims) |>
  ggplot(aes(sample = x)) +
  geom_qq(distribution = qexp, dparams = list(rate = 1)) +
  geom_qq_line(col = "red", distribution = qexp, dparam = list(rate = 1))
```

## A Simple Example of Monte Carlo Simulation

**General Recipe**:

1.  Write a function to carry out the experiment *once*.

2.  Use iteration to call that function a large number of times.

    -   Better alternative than using a `for()` loop: functional programming

        -   **Functional**: a function that takes a *another* function as an input and returns a vector.

        -   We’ll use [`purrr`](https://purrr.tidyverse.org/) for functional programming

        -   You’ve already installed it: `library(tidyverse)`

        -   `purrr` References:

            -   [`purrr` cheatsheet](https://github.com/rstudio/cheatsheets/blob/main/purrr.pdf)

            -   [R for Data Science, Chapter 21](https://r4ds.hadley.nz/iteration.html)

            -   [Advanced R Chapter 9](https://adv-r.hadley.nz/functionals.html)

        -   Today: simple application of the [`map()` function](https://purrr.tidyverse.org/reference/map.html)

3.  Store and summarize the results; set seed for replicability.

Example: compute probabilities for sum for two fair, six-sided dice.

```{r}
# write a function to carry out the experiment once

dice_sum <- \() {
  die1 <- sample(1:6, 1)
  die2 <- sample(1:6, 1)
  die1 + die2
}

# use iteration to call that function for a large number of times

nreps <- 1e4
sims <- map_dbl(1:nreps, \(i) dice_sum()) # the "i" argument for the lambda function is used to assign the position in the result vector

# summarise
tibble(x = sims) |>
  ggplot(aes(x)) +
  geom_bar()
```

## Misc

What will happen if regress $Y$ on $\hat{Y}$ ?

-   Intercept 0, slope 1

-   We can write out the objective function and see only intercept 0, slope 1 can be optimal

Simulations are important!

Except early return, specifying `return` in a R function is consider a bad style. By default, R functions return what will be printed in the last line.
